{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"water-quality-converter.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"A8wPGehtYA8y","executionInfo":{"status":"ok","timestamp":1636426656461,"user_tz":-330,"elapsed":48272,"user":{"displayName":"GIRISH DEVENDRA NAIK","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03183377526674525290"}},"outputId":"46e22ae5-bc33-49b8-c427-9ec610f580d6"},"source":["#######################################\n","###!@0 START INIT ENVIRONMENT\n","from google.colab import drive\n","drive.mount('/content/drive')\n","!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n","#!wget -q https://mirrors.estointernet.in/apache/spark/spark-3.0.3/spark-3.0.3-bin-hadoop2.7.tgz -P /content/drive/MyDrive # link wrong in blog\n","!tar xf /content/drive/Shareddrives/DA-231-O-Sem-Project-2021/lib/spark-3.0.3-bin-hadoop2.7.tgz\n","!pip install -q findspark\n","import os\n","os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n","os.environ[\"SPARK_HOME\"] = \"/content/spark-3.0.3-bin-hadoop2.7\"\n","\n","###!@0 END INIT ENVIRONMENT"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"markdown","metadata":{"id":"lw5tKEm8kuzR"},"source":["TODO: need to check if columns match with field names. pick based on column names\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Cl8Tp7pKciku","executionInfo":{"status":"ok","timestamp":1636428321749,"user_tz":-330,"elapsed":376,"user":{"displayName":"GIRISH DEVENDRA NAIK","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03183377526674525290"}},"outputId":"b5b7459a-c2e3-46dd-eaf8-b920312fa8b1"},"source":["## Imports\n","# from csv import reader\n","import csv\n","import json\n","\n","# csv file location\n","# file_input_loc = '/content/drive/Shareddrives/DA-231-O-Sem-Project-2021/data/water/water-quality-2012-raw.csv'\n","# file_ouput_loc = '/content/drive/Shareddrives/DA-231-O-Sem-Project-2021/data/water/water-quality-2012.jsonl'\n","# year= '2012'\n","# file_input_loc = '/content/drive/Shareddrives/DA-231-O-Sem-Project-2021/data/water/water-quality-2013-raw.csv'\n","# file_ouput_loc = '/content/drive/Shareddrives/DA-231-O-Sem-Project-2021/data/water/water-quality-2013.jsonl'\n","# year= '2013'\n","# file_input_loc = '/content/drive/Shareddrives/DA-231-O-Sem-Project-2021/data/water/water-quality-2014-raw.csv'\n","# file_ouput_loc = '/content/drive/Shareddrives/DA-231-O-Sem-Project-2021/data/water/water-quality-2014.jsonl'\n","# year= '2014'\n","\n","# csvfile = open(file_input_loc, 'r') #, encoding='utf-8'\n","jsonfile = open(file_ouput_loc, 'w') # , encoding='utf-8'\n","\n","fieldnames_t = (\"station_code\",\"location\",\"state\",\"temp_min\",\"temp_max\",\"temp_mean\",\"do_min\",\"do_max\",\"do_mean\"\\\n","              ,\"ph_min\",\"ph_max\",\"ph_mean\",\"conductivity_min\",\"conductivity_max\",\"conductivity_mean\",\"bod_min\",\"bod_max\",\"bod_mean\"\\\n","              ,\"nitrate_min\",\"nitrate_max\",\"nitrate_mean\",\"fecal_coliform_min\",\"fecal_coliform_max\",\"fecal_coliform_mean\",\\\n","              \"total_coliform_min\",\"total_coliform_max\",\"total_coliform_mean\", \"floride_min\",\"floride_max\",\"floride_mean\")\n","\n","fieldnames_map = {\n","    \"STATION CODE\": \"station_code\",\n","    \"LOCATIONS\": \"location\",\n","    \"STATE\": \"state\",\n","    'TEMPERATURE ºC': [\"temp_min\",\"temp_max\",\"temp_mean\"],\n","    'D.O. (mg/l)': [\"do_min\",\"do_max\",\"do_mean\"],\n","    'pH': [\"ph_min\",\"ph_max\",\"ph_mean\"],\n","     'CONDUCTIVITY (µmhos/cm)':[\"conductivity_min\",\"conductivity_max\",\"conductivity_mean\"], \n","     'B.O.D. (mg/l)': [\"bod_min\",\"bod_max\",\"bod_mean\"], \n","     'NITRATE- N+ NITRITE-N (mg/l)':[\"nitrate_min\",\"nitrate_max\",\"nitrate_mean\"],\n","      'FECAL COLIFORM (MPN/100ml)':[\"fecal_coliform_min\",\"fecal_coliform_max\",\"fecal_coliform_mean\"], \n","      'TOTAL COLIFORM (MPN/100ml)':[\"total_coliform_min\",\"total_coliform_max\",\"total_coliform_mean\"],\n","      'FLUORIDE':[\"fluoride_min\",\"fluoride_max\",\"fluoride_mean\"]\n","}\n","\n","# reader = csv.DictReader( csvfile, fieldnames)\n","# reader = csv.DictReader( csvfile)\n","\n","with open(file_input_loc, newline='') as csvfile:\n","  spamreader = csv.reader(csvfile, delimiter=',')\n","  fields=[]\n","  data_type='RIVER'\n","  for row in spamreader:\n","    # print('row >'+row[0]+'<', 'match' if row[0] == 'STATION CODE' else 'not matched')\n","    # print('row ',row)\n","    if 'WATER QUALITY OF' in row[0] or 'GROUND WATER' in row[0]:\n","      if 'MEDIUM' in row[0] and 'MINOR' in row[0] and 'RIVERS' in row[0]:\n","        data_type = 'MINOR_RIVER'\n","      elif 'RIVER' in row[0]:\n","        data_type = 'RIVER'\n","      elif 'CANAL' in row[0] and 'CREEKS' in row[0]:\n","        data_type = 'RIVER'\n","      elif 'LAKE' in row[0] and 'POND' in row[0]:\n","        data_type = 'LAKE'\n","      elif 'STREAMS' in row[0]:\n","        data_type = 'STREAMS'\n","      elif 'GROUND WATER' in row[0]:\n","        data_type = 'GROUND_WATER'\n","    elif row[0] == 'STATION CODE':\n","      fields = []\n","      # print('calculate fields:', fieldnames_map[row[0]])\n","      for index in range(0, len(row)):\n","        if row[index] == '':\n","          continue\n","        fieldVals = fieldnames_map[row[index]]\n","        # print(type(fieldVals))\n","        if type(fieldVals) == list:\n","          for fieldVal in fieldVals:\n","            fields.append(fieldVal) \n","        else:\n","          fields.append(fieldVals)\n","    else:\n","      # print('row[0]', row)\n","      if not row[0].isnumeric():\n","        continue\n","      # print('jsonRowArr', ', '.join(row))\n","      counter = 0\n","      jsonRow = {'year': year, 'data_type': data_type}\n","      for index in range(0, len(fields)):\n","        # print(index, len(row), len(fields))\n","        # print(fields[index])\n","        jsonRow[fields[index]] = row[index]\n","      # print('jsonRow', jsonRow)\n","      json.dump(jsonRow, jsonfile)\n","      jsonfile.write('\\n')\n","    # print('fields', fields)\n","\n","\n","# for row in reader:\n","#   print(row)\n","#   itemList = list(row.items())\n","#   # print(items[0][1])\n","#   if not itemList[0][1].isnumeric():\n","#     continue\n","#   # print('Data Row >>>', row)\n","#   jsonRow = {'year': year}\n","\n","#   for item in itemList:\n","#     jsonRow[item[0]] = item[1]\n","#   # print(jsonRow)\n","\n","#   # json.dump(jsonRow, jsonfile)\n","#   # jsonfile.write('\\n')\n","\n","\n","# csvfile.close()\n","jsonfile.close()\n","print('Done!!!')"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Done!!!\n"]}]}]}